"""
Orquestador Principal - Coordina la interacciÃ³n entre el Agente Consultor y el Agente Ejecutor.

Este mÃ³dulo implementa el patrÃ³n de diseÃ±o Orquestador, que coordina el flujo de trabajo
entre diferentes agentes especializados. El orquestador maneja:

1. InicializaciÃ³n y configuraciÃ³n de agentes
2. GestiÃ³n de sesiones de conversaciÃ³n
3. CoordinaciÃ³n del flujo de trabajo:
   - AnÃ¡lisis de solicitudes del usuario
   - PlanificaciÃ³n de tareas
   - EjecuciÃ³n de acciones
   - GeneraciÃ³n de respuestas

Flujo de trabajo:
1. El usuario envÃ­a una solicitud
2. El Agente Consultor analiza la solicitud y crea un plan
3. El Agente Ejecutor implementa el plan usando herramientas MCP
4. El Orquestador combina los resultados y genera una respuesta
"""
import asyncio
from typing import Dict, List, Any, Optional, AsyncGenerator
from dataclasses import dataclass
import uuid
import os
from mcp_client import MCPClient
from consultant_agent import ConsultantAgent, TaskPlan
from executor_agent import ExecutorAgent, ExecutionResult


@dataclass
class ConversationContext:
    """
    Almacena el contexto de una conversaciÃ³n activa.
    
    Atributos:
        session_id: Identificador Ãºnico de la sesiÃ³n
        consultant_thread_id: ID del hilo de conversaciÃ³n con el Agente Consultor
        executor_thread_id: ID del hilo de conversaciÃ³n con el Agente Ejecutor
        current_plan: Plan de ejecuciÃ³n actual (si existe)
        execution_history: Historial de ejecuciones en esta sesiÃ³n
    """
    session_id: str
    consultant_thread_id: str
    executor_thread_id: str
    current_plan: Optional[TaskPlan] = None
    execution_history: List[Dict[str, Any]] = None
    
    def __post_init__(self):
        """Inicializa el historial de ejecuciÃ³n si no existe"""
        if self.execution_history is None:
            self.execution_history = []


class MCPOrchestrator:
    """
    Orquestador que coordina el trabajo entre el Agente Consultor y el Agente Ejecutor.
    
    Responsabilidades:
    1. InicializaciÃ³n y configuraciÃ³n de agentes
    2. GestiÃ³n de sesiones de conversaciÃ³n
    3. CoordinaciÃ³n del flujo de trabajo
    4. Manejo de errores y excepciones
    
    Flujo de trabajo:
    1. Recibe solicitud del usuario
    2. Coordina con el Agente Consultor para anÃ¡lisis
    3. Extrae plan de ejecuciÃ³n si es necesario
    4. Coordina con el Agente Ejecutor para implementaciÃ³n
    5. Combina resultados y genera respuesta
    """
    
    def __init__(self, openai_api_key: str, model: str = "gpt-4o-mini"):
        """
        Inicializa el orquestador con la configuraciÃ³n bÃ¡sica.
        
        Args:
            openai_api_key: Clave API de OpenAI
            model: Modelo de lenguaje a utilizar
        """
        self.openai_api_key = openai_api_key
        self.model = model
        
        # Clientes y agentes
        self.mcp_client: Optional[MCPClient] = None  # Cliente para comunicaciÃ³n con MCP
        self.consultant_agent: Optional[ConsultantAgent] = None  # Agente para anÃ¡lisis y planificaciÃ³n
        self.executor_agent: Optional[ExecutorAgent] = None  # Agente para ejecuciÃ³n de tareas
        
        # Contextos de conversaciÃ³n activos
        self.conversations: Dict[str, ConversationContext] = {}
        
        # Estado de inicializaciÃ³n
        self.is_initialized = False
    
    async def initialize(self, mcp_servers_config: Dict[str, Dict[str, Any]]):
        """
        Inicializa el orquestador con la configuraciÃ³n de servidores MCP.
        
        Pasos:
        1. Inicializa el cliente MCP
        2. Conecta con los servidores MCP configurados
        3. Obtiene informaciÃ³n de herramientas disponibles
        4. Inicializa los agentes con la configuraciÃ³n necesaria
        
        Args:
            mcp_servers_config: ConfiguraciÃ³n de servidores MCP
        """
        try:
            # Inicializar cliente MCP
            self.mcp_client = MCPClient()
            await self.mcp_client.connect_to_servers(mcp_servers_config)
            
            # Obtener informaciÃ³n de herramientas
            tools_info = self.mcp_client.get_tools_info()
            all_tools = self.mcp_client.get_all_tools()
            
            # Inicializar agente consultor
            self.consultant_agent = ConsultantAgent(
                openai_api_key=self.openai_api_key,
                available_tools_info=tools_info,
                model=self.model
            )
            
            # Inicializar agente ejecutor
            self.executor_agent = ExecutorAgent(
                openai_api_key=self.openai_api_key,
                mcp_tools=all_tools,
                model=self.model
            )
            
            self.is_initialized = True
            
            print(f"ðŸš€ Orquestador inicializado exitosamente")
            print(f"ðŸ“Š Servidores MCP conectados: {list(self.mcp_client.sessions.keys())}")
            print(f"ðŸ› ï¸  Total de herramientas disponibles: {len(all_tools)}")
            
        except Exception as e:
            print(f"âŒ Error inicializando orquestador: {str(e)}")
            raise
    
    def create_conversation(self) -> str:
        """
        Crea una nueva sesiÃ³n de conversaciÃ³n.
        
        Returns:
            str: ID Ãºnico de la nueva sesiÃ³n
        """
        session_id = str(uuid.uuid4())
        
        context = ConversationContext(
            session_id=session_id,
            consultant_thread_id=f"consultant_{session_id}",
            executor_thread_id=f"executor_{session_id}"
        )
        
        self.conversations[session_id] = context
        return session_id
    
    async def process_user_request(
        self, 
        user_input: str, 
        session_id: Optional[str] = None,
        auto_execute: bool = True
    ) -> str:
        """
        Procesa una solicitud del usuario a travÃ©s del flujo completo.
        
        Flujo:
        1. AnÃ¡lisis con el Agente Consultor
        2. ExtracciÃ³n del plan de ejecuciÃ³n
        3. EjecuciÃ³n con el Agente Ejecutor (si auto_execute=True)
        4. GeneraciÃ³n de respuesta final
        
        Args:
            user_input: Solicitud del usuario
            session_id: ID de la sesiÃ³n (opcional)
            auto_execute: Si se debe ejecutar el plan automÃ¡ticamente
            
        Returns:
            str: Respuesta procesada
        """
        if not self.is_initialized:
            return "âŒ El orquestador no estÃ¡ inicializado. Llama a initialize() primero."
        
        # Crear nueva conversaciÃ³n si no se proporciona session_id
        if session_id is None:
            session_id = self.create_conversation()
        
        context = self.conversations.get(session_id)
        if not context:
            return "âŒ SesiÃ³n no encontrada."
        
        try:
            # Paso 1: Consultar con el Agente Consultor
            print(f"ðŸ¤” Consultando con el Agente Consultor...")
            consultant_response = await self.consultant_agent.process_request(
                user_input, 
                context.consultant_thread_id
            )
            
            # Paso 2: Extraer plan de ejecuciÃ³n si existe
            execution_plan = self.consultant_agent.extract_execution_plan(consultant_response)
            
            if execution_plan and auto_execute:
                print(f"ðŸ“‹ Plan de ejecuciÃ³n detectado: {execution_plan.task_description}")
                print(f"ðŸ”§ Herramientas requeridas: {', '.join(execution_plan.required_tools)}")
                
                # Guardar el plan en el contexto
                context.current_plan = execution_plan
                
                # Paso 3: Ejecutar el plan con el Agente Ejecutor
                execution_prompt = f"""
Ejecuta esta tarea: {execution_plan.task_description}

Pasos a seguir:
{chr(10).join([f"{i+1}. {step.get('description', step.get('action', ''))}" for i, step in enumerate(execution_plan.execution_steps)])}

Resultado esperado: {execution_plan.expected_outcome}
"""
                
                print(f"âš¡ Ejecutando con el Agente Ejecutor...")
                execution_result = await self.executor_agent.execute_single_task(
                    execution_prompt,
                    context.executor_thread_id
                )
                
                # Registrar en el historial
                context.execution_history.append({
                    "user_input": user_input,
                    "consultant_response": consultant_response,
                    "execution_plan": execution_plan,
                    "execution_result": execution_result,
                    "timestamp": asyncio.get_event_loop().time()
                })
                
                # Combinar respuestas
                final_response = f"""
**AnÃ¡lisis de la solicitud:**
{consultant_response}

**Resultado de la ejecuciÃ³n:**
{execution_result}
"""
                return final_response
            
            else:
                # No hay plan de ejecuciÃ³n o auto_execute=False
                if execution_plan and not auto_execute:
                    context.current_plan = execution_plan
                    return f"""
{consultant_response}

ðŸ’¡ **Plan de ejecuciÃ³n preparado pero no ejecutado automÃ¡ticamente.**
Usa `execute_current_plan()` para ejecutarlo o `process_user_request()` con `auto_execute=True`.
"""
                else:
                    # Respuesta directa sin ejecuciÃ³n
                    return consultant_response
            
        except Exception as e:
            error_msg = f"âŒ Error procesando solicitud: {str(e)}"
            print(error_msg)
            return error_msg
    
    async def execute_current_plan(self, session_id: str) -> str:
        """
        Ejecuta el plan actual de una sesiÃ³n.
        
        Args:
            session_id: ID de la sesiÃ³n
            
        Returns:
            str: Resultado de la ejecuciÃ³n
        """
        context = self.conversations.get(session_id)
        if not context or not context.current_plan:
            return "âŒ No hay plan de ejecuciÃ³n disponible en esta sesiÃ³n."
        
        try:
            plan = context.current_plan
            execution_prompt = f"""
Ejecuta esta tarea: {plan.task_description}

Pasos a seguir:
{chr(10).join([f"{i+1}. {step.get('description', step.get('action', ''))}" for i, step in enumerate(plan.execution_steps)])}

Resultado esperado: {plan.expected_outcome}
"""
            
            print(f"âš¡ Ejecutando plan: {plan.task_description}")
            execution_result = await self.executor_agent.execute_single_task(
                execution_prompt,
                context.executor_thread_id
            )
            
            # Limpiar el plan actual
            context.current_plan = None
            
            return f"âœ… **Plan ejecutado exitosamente:**\n\n{execution_result}"
            
        except Exception as e:
            return f"âŒ Error ejecutando plan: {str(e)}"
    
    async def stream_execution(
        self, 
        user_input: str, 
        session_id: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """
        Procesa una solicitud con streaming de resultados.
        
        Similar a process_user_request pero devuelve los resultados
        en tiempo real a medida que se generan.
        
        Args:
            user_input: Solicitud del usuario
            session_id: ID de la sesiÃ³n (opcional)
            
        Yields:
            str: Fragmentos de la respuesta en tiempo real
        """
        if not self.is_initialized:
            yield "âŒ El orquestador no estÃ¡ inicializado."
            return
        
        if session_id is None:
            session_id = self.create_conversation()
        
        context = self.conversations.get(session_id)
        if not context:
            yield "âŒ SesiÃ³n no encontrada."
            return
        
        try:
            # Consultar primero
            yield "ðŸ¤” Analizando solicitud...\n"
            
            consultant_response = await self.consultant_agent.process_request(
                user_input, 
                context.consultant_thread_id
            )
            
            yield f"**AnÃ¡lisis:**\n{consultant_response}\n\n"
            
            # Extraer y ejecutar plan si existe
            execution_plan = self.consultant_agent.extract_execution_plan(consultant_response)
            
            if execution_plan:
                yield f"ðŸ“‹ **Ejecutando plan:** {execution_plan.task_description}\n\n"
                
                execution_prompt = f"Ejecuta: {execution_plan.task_description}"
                
                async for chunk in self.executor_agent.stream_execution(
                    execution_prompt,
                    context.executor_thread_id
                ):
                    yield chunk
            
        except Exception as e:
            yield f"\nâŒ Error: {str(e)}"
    
    def get_conversation_summary(self, session_id: str) -> Dict[str, Any]:
        """Obtener resumen de una conversaciÃ³n"""
        context = self.conversations.get(session_id)
        if not context:
            return {"error": "SesiÃ³n no encontrada"}
        
        return {
            "session_id": session_id,
            "total_executions": len(context.execution_history),
            "current_plan": context.current_plan is not None,
            "last_execution": context.execution_history[-1] if context.execution_history else None
        }
    
    def list_active_conversations(self) -> List[str]:
        """Listar conversaciones activas"""
        return list(self.conversations.keys())
    
    def get_available_tools_info(self) -> Dict[str, List[str]]:
        """Obtener informaciÃ³n de herramientas disponibles"""
        if self.mcp_client:
            return self.mcp_client.get_tools_info()
        return {}
    
    async def close(self):
        """Cerrar todas las conectiones y limpiar recursos"""
        if self.mcp_client:
            await self.mcp_client.close()
        
        self.conversations.clear()
        self.is_initialized = False
        print("ðŸ”„ Orquestador cerrado correctamente")
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()